{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ba7105",
   "metadata": {},
   "source": [
    "# Understanding the Impact of Image Quality and Distance of Objects to Object Detection Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bd6c9",
   "metadata": {},
   "source": [
    "***A reproduction*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c63682",
   "metadata": {},
   "source": [
    "## Downscale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d24d59",
   "metadata": {},
   "source": [
    "Folder expansion: Some datasets come with multiple subfolders not needed for the purposes of our reproduction study. Example:\n",
    "\n",
    "```\n",
    "img\n",
    "|_dir1 \n",
    "    |_img1.png\n",
    "    |_img2.png\n",
    "    |_img3.png\n",
    "|_dir2\n",
    "    |_img1.png\n",
    "    |_img2.png\n",
    "    |_img3.png\n",
    "|_dir3\n",
    "(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "e22dc3d1",
   "metadata": {},
   "source": [
    "from data_processing.expand_folders import expand_folders\n",
    "expand_folders(\"../datasets/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c2e06b67",
   "metadata": {},
   "source": [
    "### Spatial and Amplitudinal Resolution Downsampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302f025",
   "metadata": {},
   "source": [
    "Spatial - 1.42x Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "id": "058db19b",
   "metadata": {},
   "source": [
    "from data_processing.expand_dataset import expand_dataset\n",
    "\n",
    "INPUT_IMAGE_DIR = \"../datasets/ECP/day/img/val\"\n",
    "INPUT_LABEL_DIR = \"../datasets/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\"\n",
    "DATASET_OUTPUT_DIR = \"../datasets/quick_test_new_1\"\n",
    "label_values_to_scale = [\"imageheight\", \"imagewidth\", \"x0\", \"y0\", \"x1\", \"y1\"]\n",
    "OUTPUT_IMG_DIR = f\"{DATASET_OUTPUT_DIR}/img\"\n",
    "OUTPUT_LABEL_DIR = f\"{DATASET_OUTPUT_DIR}/labels\"\n",
    "\n",
    "expand_dataset(\n",
    "    input_dir=INPUT_IMAGE_DIR,\n",
    "    label_dir=INPUT_LABEL_DIR,\n",
    "    label_values_to_scale=label_values_to_scale,\n",
    "    output_img_dir=OUTPUT_IMG_DIR,\n",
    "    output_label_dir=OUTPUT_LABEL_DIR,\n",
    "    expansion=\"spatial\",\n",
    "    scale_factors=[0.01], \n",
    "    qp_values=[],\n",
    "    subsample_spatial=False,\n",
    "    subsample_amplitudinal=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "326eaffb",
   "metadata": {},
   "source": [
    "Amplitudinal Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "id": "c67ba863d04e8c6c",
   "metadata": {},
   "source": [
    "from data_processing.expand_dataset import expand_dataset\n",
    "\n",
    "INPUT_IMAGE_DIR = \"../datasets/ECP/day/img/val\"\n",
    "INPUT_LABEL_DIR = \"../datasets/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\"\n",
    "DATASET_OUTPUT_DIR = \"../datasets/eurocity_original_amplitudinally_compressed\"\n",
    "label_values_to_scale = [\"imageheight\", \"imagewidth\", \"x0\", \"y0\", \"x1\", \"y1\"]\n",
    "OUTPUT_IMG_DIR = f\"{DATASET_OUTPUT_DIR}/img\"\n",
    "OUTPUT_LABEL_DIR = f\"{DATASET_OUTPUT_DIR}/labels\"\n",
    "COMPRESSION_METADATA_DIR = f\"{DATASET_OUTPUT_DIR}/metadata\"\n",
    "\n",
    "qp_values = [16, 24, 34, 38, 46] #values from paper\n",
    "\n",
    "expand_dataset(\n",
    "    input_dir=INPUT_IMAGE_DIR,\n",
    "    label_dir=INPUT_LABEL_DIR,\n",
    "    label_values_to_scale=label_values_to_scale,\n",
    "    scale_factors=[],\n",
    "    output_img_dir=OUTPUT_IMG_DIR,\n",
    "    output_label_dir=OUTPUT_LABEL_DIR,\n",
    "    metadata_dir=COMPRESSION_METADATA_DIR,\n",
    "    qp_values=qp_values, #values from paper\n",
    "    expansion = \"amplitudinal\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b61c61eb",
   "metadata": {},
   "source": [
    "Mixed Downsampling - Combined Set of both"
   ]
  },
  {
   "cell_type": "code",
   "id": "114e8eb846b4659e",
   "metadata": {},
   "source": [
    "from data_processing.expand_dataset import expand_dataset\n",
    "\n",
    "# INPUT_IMAGE_DIR = \"../datasets/ECP/day/img/val\"\n",
    "INPUT_IMAGE_DIR = \"/Volumes/NEW VOLUME/ECP/day/img/val\"\n",
    "# INPUT_LABEL_DIR = \"../datasets/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\"\n",
    "INPUT_LABEL_DIR = \"/Volumes/NEW VOLUME/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\"\n",
    "DATASET_OUTPUT_DIR = \"datasets/quick_test_new_2\"\n",
    "label_values_to_scale = [\"imageheight\", \"imagewidth\", \"x0\", \"y0\", \"x1\", \"y1\"]\n",
    "OUTPUT_IMG_DIR = f\"{DATASET_OUTPUT_DIR}/img\"\n",
    "OUTPUT_LABEL_DIR = f\"{DATASET_OUTPUT_DIR}/labels\"\n",
    "COMPRESSION_METADATA_DIR = f\"{DATASET_OUTPUT_DIR}/metadata\"\n",
    "qp_values = [16, 24, 34, 38, 46] #values from paper\n",
    "\n",
    "expand_dataset(\n",
    "    input_dir=INPUT_IMAGE_DIR,\n",
    "    label_dir=INPUT_LABEL_DIR,\n",
    "    label_values_to_scale=label_values_to_scale,\n",
    "    output_img_dir=OUTPUT_IMG_DIR,\n",
    "    output_label_dir=OUTPUT_LABEL_DIR,\n",
    "    metadata_dir=COMPRESSION_METADATA_DIR,\n",
    "    scale_factors=[1, 720.0/1024, 854.0/ 1920], #values from paper\n",
    "    qp_values=qp_values, #values from paper\n",
    "    expansion=\"mixed\", \n",
    "    subsample_spatial=True,\n",
    "    subsample_amplitudinal=False,\n",
    "    num_images=100\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "703a057a",
   "metadata": {},
   "source": [
    "### Convert to YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8663a37",
   "metadata": {},
   "source": [
    "from datasets.to_yolo_format import to_yolo_format\n",
    "\n",
    "labels_dir = \"datasets/quick_test_new_2/labels\"  # YOLO output\n",
    "images_dir = \"datasets/quick_test_new_2/img\"  # Images directory\n",
    "dataset_root = \"datasets/quick_test_new_2\"          # Root directory\n",
    "split = 0.8\n",
    "\n",
    "\n",
    "to_yolo_format(\n",
    "    labels_dir=labels_dir,\n",
    "    images_dir=images_dir,\n",
    "    dataset_root=dataset_root,\n",
    "    split=split,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a57854c",
   "metadata": {},
   "source": [
    "## Train/Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2259e3",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "id": "ca7ee050",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "yolov5_dir = os.path.abspath('yolov5')\n",
    "if yolov5_dir not in sys.path:\n",
    "    sys.path.append(yolov5_dir)\n",
    "from yolov5.train import main, Callbacks\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'mps' if torch.mps.is_available() else device\n",
    "cfg = \"ra_yolo5l.yaml\"  \n",
    "average_image_size = 740 # Calculate average image size from dataset\n",
    "opt = argparse.Namespace(\n",
    "    weights='yolov5l.pt',  # Model weights\n",
    "    cfg=cfg,  # Empty to use weights' default config\n",
    "    data=os.path.abspath('../datasets/quick_test_new_1/data.yaml'),  # Absolute path to dataset\n",
    "    hyp=os.path.join(yolov5_dir, 'data/hyps/hyp.scratch-low.yaml'),  # Hyperparameters\n",
    "    epochs=15,\n",
    "    batch_size=1,\n",
    "    imgsz=average_image_size,  # Input image size\n",
    "    rect=False,\n",
    "    resume=False,\n",
    "    nosave=False,\n",
    "    noval=False,\n",
    "    noautoanchor=True,\n",
    "    noplots=False,\n",
    "    evolve=None,\n",
    "    evolve_population=os.path.join(yolov5_dir, 'data/hyps'),\n",
    "    resume_evolve=None,\n",
    "    bucket='',\n",
    "    cache=None,\n",
    "    image_weights=False,\n",
    "    device=device,\n",
    "    multi_scale=False,\n",
    "    single_cls=False,\n",
    "    optimizer='SGD',\n",
    "    sync_bn=False,\n",
    "    workers=8,\n",
    "    project=os.path.join(yolov5_dir, 'runs/train'),\n",
    "    name='exp',\n",
    "    exist_ok=True,\n",
    "    quad=False,\n",
    "    cos_lr=False,\n",
    "    label_smoothing=0.0,\n",
    "    patience=100,\n",
    "    freeze=[0],  \n",
    "    save_period=1,\n",
    "    seed=0,\n",
    "    local_rank=-1,\n",
    "    ra_yolo=True,\n",
    "    entity=None,\n",
    "    upload_dataset=False,\n",
    "    bbox_interval=-1,\n",
    "    artifact_alias='latest',\n",
    "    ndjson_console=False,\n",
    "    ndjson_file=False\n",
    ")\n",
    "\n",
    "main(opt, callbacks=Callbacks())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "57b06c1c",
   "metadata": {},
   "source": [
    "#### Extract results"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5b31f3f",
   "metadata": {},
   "source": [
    "import torch \n",
    "from yolov5.val import run as yolov5_run_val\n",
    "\n",
    "data = 'datasets/test/data.yaml'  # Path to your dataset YAML file\n",
    "weights = 'yolov5/runs/train/exp/weights/best.pt'      # Path to your model weights file\n",
    "batch_size = 1             # Batch size for validation           # Image size for inference\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'mps' if torch.mps.is_available() else device\n",
    "confidence_threshold = 0.1\n",
    "iou_threshold = 0.6\n",
    "average_image_size = 740 # Calculate average image size from dataset\n",
    "\n",
    "# Run the validation\n",
    "results, maps, times = yolov5_run_val(\n",
    "    data=data,                      # Dataset configuration\n",
    "    imgsz=average_image_size,       # Image size for inference\n",
    "    conf_thres=confidence_threshold,# confidence threshold\n",
    "    iou_thres=iou_threshold,        # NMS IoU threshold\n",
    "    weights=weights,                # Model weights\n",
    "    batch_size=batch_size,          # Batch size\n",
    "    device=device,                  # Device to run on\n",
    "    task='val',                     # Task type: validation\n",
    "    save_txt=True,                  # Don’t save results to text files\n",
    "    save_json=True,                 # Don’t save results to JSON\n",
    "    plots=True,                     # Generate plots (saved to runs/val/)\n",
    "    ra_yolo=True\n",
    ")\n",
    "\n",
    "# Extract metrics from r\n",
    "mp, mr, map50, map, box_loss, obj_loss, cls_loss = results  # Mean Precision, Mean Recall, mAP@0.5, mAP@0.5:0.95\n",
    "print(f'Mean Precision: {mp:.4f}')\n",
    "print(f'Mean Recall: {mr:.4f}')\n",
    "print(f'mAP@0.5: {map50:.4f}')\n",
    "print(f'mAP@0.5:0.95: {map:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb822c81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T19:15:22.015098Z",
     "start_time": "2025-06-20T19:15:15.795880Z"
    }
   },
   "source": [
    "from data_processing.extract_model_predictions import extract_predictions_from_run\n",
    "\n",
    "predictions, labels = extract_predictions_from_run(json_path=\"yolov5/runs/val/exp5/best_predictions.json\", label_dir=\"datasets/test/labels\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "91fa47c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T19:18:38.298017Z",
     "start_time": "2025-06-20T19:18:37.101451Z"
    }
   },
   "source": [
    "from data_processing.extract_model_predictions import create_predictions_dataframe\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "df = create_predictions_dataframe(predictions, labels, \"datasets/test/metadata\", iou_threshold=0.2)\n",
    "\n",
    "len(df[df['tp'] > 0]), df.shape[0]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2498/2498 [00:01<00:00, 2430.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 12127)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d83e6f0a",
   "metadata": {},
   "source": [
    "from metrics.extract_metrics import compute_map50\n",
    "\n",
    "map50 = compute_map50(df, plot=True)\n",
    "map50"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8894b32",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb5840",
   "metadata": {},
   "source": [
    "#### Reproducing figures from the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc6f29",
   "metadata": {},
   "source": [
    "#### Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "id": "46314223",
   "metadata": {},
   "source": [
    "from visualization.xy_lineplot import basic_lineplot, multi_lineplot\n",
    "\n",
    "data_dict = {\n",
    "    \"EuroCity Normal Res\": ([0, 1, 2, 3, 4, 5], [0, 1, 4, 9, 16, 25], [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]),\n",
    "    \"EuroCity 1.42 \": ([0, 1, 2, 6, 8, 9], [0, 1, 5, 10, 16, 27] , [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]),\n",
    "    \"Eurocity 1.87\": ([0, 2, 3, 5, 7, 9], [0, 1, 2, 3, 12, 20], [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]),\n",
    "}\n",
    "## Figure 5 in the paper\n",
    "multi_lineplot(data_dict, xlabel=\"Megabytes/Image\", ylabel=\"map@50 - All Category\")\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Group by both 'spatial_res' and 'amplitudal_res'\n",
    "grouped = df.groupby(['spatial_res', 'amplitudal_res'])\n",
    "\n",
    "# Step 2: Compute mean megabytes and mAP@50 per group\n",
    "plot_data = defaultdict(lambda: ([], [], []))  # spatial_res -> (x_list, y_list)\n",
    "\n",
    "for (spatial_res, amplitudal_res), group in grouped:\n",
    "    print(f\"Processing spatial_res: {spatial_res}, amplitudal_res: {amplitudal_res}\")\n",
    "    map50 = compute_map50(group, plot=False)  # Compute mAP@50 for the group\n",
    "    megabytes = group['image_size_mb'].mean()\n",
    "    plot_data[f'Eurocity: Scaled {spatial_res}'][0].append(megabytes)\n",
    "    plot_data[f'Eurocity: Scaled {spatial_res}'][1].append(map50)\n",
    "    plot_data[f'Eurocity: Scaled {spatial_res}'][2].append(f'QP{amplitudal_res}')\n",
    "\n",
    "\n",
    "# Step 3: Sort each line’s data by megabytes to ensure correct plotting\n",
    "for spatial_res in plot_data:\n",
    "    megabytes, map_scores, texts = plot_data[spatial_res]\n",
    "    sorted_pairs = sorted(zip(megabytes, map_scores, texts))\n",
    "    x_sorted, y_sorted, texts = zip(*sorted_pairs)\n",
    "    plot_data[spatial_res] = (list(x_sorted), list(y_sorted), list(texts))\n",
    "\n",
    "multi_lineplot(\n",
    "    data_dict=plot_data,\n",
    "    xlabel=\"Megabytes/Image\",\n",
    "    ylabel=\"mAP@50 - All Category\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb13fa3e",
   "metadata": {},
   "source": [
    "from visualization.xy_lineplot import basic_lineplot, multi_lineplot\n",
    "\n",
    "data_dict = {\n",
    "    \"EuroCity Original\": ([0, 1, 2, 3, 4, 5], [25, 16, 10, 7, 3, 1]),\n",
    "    \"EuroCity 1.42 -> Finetuned Model\": ([0, 1, 2, 6, 8, 9], [24, 13, 10, 5, 1, 0]),\n",
    "}\n",
    "## Figure 5 in the paper \n",
    "multi_lineplot(data_dict, xlabel=\"Distance(m)\", ylabel=\"Recall-Pedestrian\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
