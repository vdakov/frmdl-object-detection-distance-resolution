{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ba7105",
   "metadata": {},
   "source": [
    "# Understanding the Impact of Image Quality and Distance of Objects to Object Detection Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bd6c9",
   "metadata": {},
   "source": [
    "***A reproduction*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c63682",
   "metadata": {},
   "source": [
    "## Downscale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d24d59",
   "metadata": {},
   "source": [
    "Folder expansion: Some datasets come with multiple subfolders not needed for the purposes of our reproduction study. Example:\n",
    "\n",
    "```\n",
    "img\n",
    "|_dir1 \n",
    "    |_img1.png\n",
    "    |_img2.png\n",
    "    |_img3.png\n",
    "|_dir2\n",
    "    |_img1.png\n",
    "    |_img2.png\n",
    "    |_img3.png\n",
    "|_dir3\n",
    "(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22dc3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.expand_folders import expand_folders\n",
    "expand_folders(\"../datasets/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e06b67",
   "metadata": {},
   "source": [
    "### Spatial and Amplitudinal Resolution Downsampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302f025",
   "metadata": {},
   "source": [
    "Spatial - 1.42x Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058db19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.expand_dataset import expand_dataset\n",
    "\n",
    "INPUT_IMAGE_DIR = \"../datasets/ECP/day/img/val\"\n",
    "INPUT_LABEL_DIR = \"../datasets/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\"\n",
    "DATASET_OUTPUT_DIR = \"../datasets/spatially_compressed\"\n",
    "label_values_to_scale = [\"imageheight\", \"imagewidth\", \"x0\", \"y0\", \"x1\", \"y1\"]\n",
    "OUTPUT_IMG_DIR = f\"{DATASET_OUTPUT_DIR}/img\"\n",
    "OUTPUT_LABEL_DIR = f\"{DATASET_OUTPUT_DIR}/labels\"\n",
    "\n",
    "expand_dataset(\n",
    "    input_dir=INPUT_IMAGE_DIR,\n",
    "    label_dir=INPUT_LABEL_DIR,\n",
    "    label_values_to_scale=label_values_to_scale,\n",
    "    output_img_dir=OUTPUT_IMG_DIR,\n",
    "    output_label_dir=OUTPUT_LABEL_DIR,\n",
    "    scale_factors=[720.0/1024], #value from paper \n",
    "    qp_values=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326eaffb",
   "metadata": {},
   "source": [
    "Amplitudinal Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.expand_dataset import expand_dataset\n",
    "\n",
    "INPUT_IMAGE_DIR = \"../datasets/ECP/day/img/val\"\n",
    "INPUT_LABEL_DIR = \"../datasets/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\"\n",
    "DATASET_OUTPUT_DIR = \"../datasets/eurocity_original_amplitudinally_compressed\"\n",
    "label_values_to_scale = [\"imageheight\", \"imagewidth\", \"x0\", \"y0\", \"x1\", \"y1\"]\n",
    "OUTPUT_IMG_DIR = f\"{DATASET_OUTPUT_DIR}/img\"\n",
    "OUTPUT_LABEL_DIR = f\"{DATASET_OUTPUT_DIR}/labels\"\n",
    "\n",
    "qp_values = [16, 24, 34, 38, 46] #values from paper\n",
    "\n",
    "expand_dataset(\n",
    "    input_dir=INPUT_IMAGE_DIR,\n",
    "    label_dir=INPUT_LABEL_DIR,\n",
    "    label_values_to_scale=label_values_to_scale,\n",
    "    scale_factors=[],\n",
    "    output_img_dir=OUTPUT_IMG_DIR,\n",
    "    output_label_dir=OUTPUT_LABEL_DIR,\n",
    "    qp_values=qp_values, #values from paper\n",
    "    expansion = \"amplitudinal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c61eb",
   "metadata": {},
   "source": [
    "Mixed Downsampling - Combined Set of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f356ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.expand_dataset import expand_dataset\n",
    "\n",
    "INPUT_IMAGE_DIR = \"../datasets/ECP/day/img/val\"\n",
    "INPUT_LABEL_DIR = \"../datasets/ECP2dot5D_day_labels_val/ECP2dot5D/day/labels/val\"\n",
    "DATASET_OUTPUT_DIR = \"../datasets/mixed\"\n",
    "label_values_to_scale = [\"imageheight\", \"imagewidth\", \"x0\", \"y0\", \"x1\", \"y1\"]\n",
    "OUTPUT_IMG_DIR = f\"{DATASET_OUTPUT_DIR}/img\"\n",
    "OUTPUT_LABEL_DIR = f\"{DATASET_OUTPUT_DIR}/labels\"\n",
    "qp_values = [16, 24, 34, 38, 46] #values from paper\n",
    "\n",
    "expand_dataset(\n",
    "    input_dir=INPUT_IMAGE_DIR,\n",
    "    label_dir=INPUT_LABEL_DIR,\n",
    "    label_values_to_scale=label_values_to_scale,\n",
    "    output_img_dir=OUTPUT_IMG_DIR,\n",
    "    output_label_dir=OUTPUT_LABEL_DIR,\n",
    "    scale_factors=[1, 720.0/1024, 854.0/ 1920], #values from paper\n",
    "    qp_values=[0, 5, 10, 16, 20, 24, 28, 34, 38, 42, 46, 51], #values from paper\n",
    "    expansion=\"mixed\", \n",
    "    subsample_spatial=True,\n",
    "    subsample_amplitudinal=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57854c",
   "metadata": {},
   "source": [
    "## Train/Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2259e3",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7ee050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=ra_yolo5l.yaml, data=/home/vasil/Desktop/frmdl/datasets/mixed/data.yaml, hyp=/home/vasil/Desktop/frmdl/frmdl-object-detection-distance-resolution/yolov5/data/hyps/hyp.scratch-low.yaml, epochs=1, batch_size=1, imgsz=800, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=/home/vasil/Desktop/frmdl/frmdl-object-detection-distance-resolution/yolov5/data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=cuda, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/home/vasil/Desktop/frmdl/frmdl-object-detection-distance-resolution/yolov5/runs/train, name=exp, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, ra_yolo=True, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 1 commit. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Invalid CUDA '--device cuda' requested, use '--device cpu' or pass valid CUDA device(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     13\u001b[39m cfg = \u001b[33m\"\u001b[39m\u001b[33mra_yolo5l.yaml\u001b[39m\u001b[33m\"\u001b[39m  \n\u001b[32m     14\u001b[39m opt = argparse.Namespace(\n\u001b[32m     15\u001b[39m     weights=\u001b[33m'\u001b[39m\u001b[33myolov5l.pt\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# Model weights\u001b[39;00m\n\u001b[32m     16\u001b[39m     cfg=cfg,  \u001b[38;5;66;03m# Empty to use weights' default config\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \n\u001b[32m     59\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/frmdl/frmdl-object-detection-distance-resolution/yolov5/train.py:682\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(opt, callbacks)\u001b[39m\n\u001b[32m    679\u001b[39m     opt.save_dir = \u001b[38;5;28mstr\u001b[39m(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# DDP mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m device = \u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m LOCAL_RANK != -\u001b[32m1\u001b[39m:\n\u001b[32m    684\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mis not compatible with YOLOv5 Multi-GPU DDP training\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/frmdl/frmdl-object-detection-distance-resolution/yolov5/utils/torch_utils.py:124\u001b[39m, in \u001b[36mselect_device\u001b[39m\u001b[34m(device, batch_size, newline)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m device:  \u001b[38;5;66;03m# non-cpu device requested\u001b[39;00m\n\u001b[32m    123\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[33m\"\u001b[39m] = device  \u001b[38;5;66;03m# set environment variable - must be before assert is_available()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m torch.cuda.is_available() \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.device_count() >= \u001b[38;5;28mlen\u001b[39m(device.replace(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)), (\n\u001b[32m    125\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid CUDA \u001b[39m\u001b[33m'\u001b[39m\u001b[33m--device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m requested, use \u001b[39m\u001b[33m'\u001b[39m\u001b[33m--device cpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or pass valid CUDA device(s)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    126\u001b[39m     )\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.is_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[32m    129\u001b[39m     devices = device.split(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# range(torch.cuda.device_count())  # i.e. 0,1,6,7\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: Invalid CUDA '--device cuda' requested, use '--device cpu' or pass valid CUDA device(s)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "yolov5_dir = os.path.abspath('yolov5')\n",
    "if yolov5_dir not in sys.path:\n",
    "    sys.path.append(yolov5_dir)\n",
    "from yolov5.train import main, Callbacks\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cuda'\n",
    "print(torch.cuda.is_available())\n",
    "cfg = \"ra_yolo5l.yaml\"  \n",
    "opt = argparse.Namespace(\n",
    "    weights='yolov5l.pt',  # Model weights\n",
    "    cfg=cfg,  # Empty to use weights' default config\n",
    "    data=os.path.abspath('../datasets/mixed/data.yaml'),  # Absolute path to dataset\n",
    "    hyp=os.path.join(yolov5_dir, 'data/hyps/hyp.scratch-low.yaml'),  # Hyperparameters\n",
    "    epochs=1,\n",
    "    batch_size=1,\n",
    "    imgsz=800,  # Fixed from invalid imgsz=4\n",
    "    rect=False,\n",
    "    resume=False,\n",
    "    nosave=False,\n",
    "    noval=False,\n",
    "    noautoanchor=False,\n",
    "    noplots=False,\n",
    "    evolve=None,\n",
    "    evolve_population=os.path.join(yolov5_dir, 'data/hyps'),\n",
    "    resume_evolve=None,\n",
    "    bucket='',\n",
    "    cache=None,\n",
    "    image_weights=False,\n",
    "    device=device,\n",
    "    multi_scale=False,\n",
    "    single_cls=False,\n",
    "    optimizer='SGD',\n",
    "    sync_bn=False,\n",
    "    workers=8,\n",
    "    project=os.path.join(yolov5_dir, 'runs/train'),\n",
    "    name='exp',\n",
    "    exist_ok=True,\n",
    "    quad=False,\n",
    "    cos_lr=False,\n",
    "    label_smoothing=0.0,\n",
    "    patience=100,\n",
    "    freeze=[0],  # Freeze first 10 layers\n",
    "    save_period=-1,\n",
    "    seed=0,\n",
    "    local_rank=-1,\n",
    "    ra_yolo=True,\n",
    "    entity=None,\n",
    "    upload_dataset=False,\n",
    "    bbox_interval=-1,\n",
    "    artifact_alias='latest',\n",
    "    ndjson_console=False,\n",
    "    ndjson_file=False\n",
    "\n",
    ")\n",
    "\n",
    "main(opt, callbacks=Callbacks())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b06c1c",
   "metadata": {},
   "source": [
    "#### Extract results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b31f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from yolov5.val import run  as yolov5_run_val\n",
    "\n",
    "data = '../datasets/mixed/data.yaml'  # Path to your dataset YAML file\n",
    "weights = 'yolov5n.pt'      # Path to your model weights file\n",
    "batch_size = 16             # Batch size for validation\n",
    "imgsz = 4                # Image size for inference\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Automatically select device\n",
    "\n",
    "# Run the validation\n",
    "results, maps, times = yolov5_run_val(\n",
    "    data=data,              # Dataset configuration\n",
    "    weights=weights,        # Model weights\n",
    "    batch_size=batch_size,  # Batch size\n",
    "    imgsz=imgsz,            # Image size\n",
    "    device=device,          # Device to run on\n",
    "    task='val',             # Task type: validation\n",
    "    save_txt=True,         # Don’t save results to text files\n",
    "    save_json=True,        # Don’t save results to JSON\n",
    "    plots=True,             # Generate plots (saved to runs/val/)\n",
    ")\n",
    "\n",
    "# Extract metrics from r\n",
    "mp, mr, map50, map, box_loss, obj_loss, cls_loss = results  # Mean Precision, Mean Recall, mAP@0.5, mAP@0.5:0.95\n",
    "print(f'Mean Precision: {mp:.4f}')\n",
    "print(f'Mean Recall: {mr:.4f}')\n",
    "print(f'mAP@0.5: {map50:.4f}')\n",
    "print(f'mAP@0.5:0.95: {map:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb822c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, im_names, label_names = extract_predictions_from_run(json_path=\"runs/val/exp/predictions.json\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8894b32",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb5840",
   "metadata": {},
   "source": [
    "#### Reproducing figures from the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc6f29",
   "metadata": {},
   "source": [
    "#### Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46314223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.xy_lineplot import basic_lineplot, multi_lineplot\n",
    "\n",
    "data_dict = {\n",
    "    \"EuroCity Original -> Finetuned Model\": ([0, 1, 2, 3, 4, 5], [0, 1, 4, 9, 16, 25]),\n",
    "    \"EuroCity 1.42 -> Finetuned Model\": ([0, 1, 2, 6, 8, 9], [0, 1, 5, 10, 16, 27]),\n",
    "    \"EuroCity Original\": ([0, 2, 3, 5, 7, 9], [0, 1, 2, 3, 12, 20]), \n",
    "    \"EuroCity 1.42\": ([0, 2, 2, 4, 8, 9], [0, 1, 4, 9, 16, 25])\n",
    "}\n",
    "## Figure 5 in the paper \n",
    "multi_lineplot(data_dict, xlabel=\"Megabytes/Image\", ylabel=\"map@50 - All Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb13fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.xy_lineplot import basic_lineplot, multi_lineplot\n",
    "\n",
    "data_dict = {\n",
    "    \"EuroCity Original\": ([0, 1, 2, 3, 4, 5], [25, 16, 10, 7, 3, 1]),\n",
    "    \"EuroCity 1.42 -> Finetuned Model\": ([0, 1, 2, 6, 8, 9], [24, 13, 10, 5, 1, 0]),\n",
    "}\n",
    "## Figure 5 in the paper \n",
    "multi_lineplot(data_dict, xlabel=\"Distance(m)\", ylabel=\"Recall-Pedestrian\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsait-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
